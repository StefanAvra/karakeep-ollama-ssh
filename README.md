I use this for serving an LLM with Ollama from my local machine to my remote server where I have Karakeep setup in Coolify. This way Karakeep can utilize the LLM to generate tags and make AI summaries for my bookmarks.

# todo
- cleanup double output when closing
- display some kind of progress when ollama generates text 
- maybe kill all ollama processes after closing?
- rewrite with nicer TUI?
